---
title: "Quickstart"
description: "Get started with the Kisho SDK in under 2 minutes"
---

## Setup your environment

Learn how to set up and use the Kisho SDK for advanced NLP tasks.

### Installation and Configuration

Install the Kisho SDK using pip:

```bash
pip install kisho
```

#### Set up your API keys

Create a `.env` file in your project root and add your API key:

```bash
KISHO_API_KEY=your_kisho_api_key_here
```

## Basic Usage

#### Initialize your LLM client

Import and initialize the Kisho-traced OpenAI client. This will replace the OpenAI client in your code.

```python
from kisho import trace_oai

client = trace_oai(api_key=os.environ['OPENAI_API_KEY'])
```

#### Create traced functions

Use the `@traced_function` decorator to automatically trace your functions:

```python
from kisho import traced_function

@traced_function
def example_function(input_var):
    # Your function implementation here
    pass
```

#### Add metadata to LLM calls

You can set agent_id, metadata, and tags for each LLM call.

```python
response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a topic extraction expert. Identify the main topics in the given text."},
            {"role": "user", "content": f"Extract the main topics from this text and return them as a comma-separated list:\n{query}"}
        ],
        agent_id="topic_extraction_agent",
        metadata={"purpose": "topic extraction"},
        tags=["nlp", "topics"]
    )
```

## Sample Implementation

Here's a basic example of how to use the Kisho SDK for a multi-step NLP analysis:

```python
import os
from dotenv import load_dotenv
from kisho import trace_oai, traced_function

# Load environment variables and set up the client
load_dotenv()
os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')
os.environ['KISHO_API_KEY'] = "your-kisho-api-key"
client = trace_oai(api_key=os.environ['OPENAI_API_KEY'])

@traced_function
def analyze_text(query):
    return {
        "sentiment": sentiment_analysis(query),
        "topics": topic_extraction(query)
    }

@traced_function
def sentiment_analysis(query):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a sentiment analysis expert. Provide a sentiment score from -1 (very negative) to 1 (very positive)."},
            {"role": "user", "content": f"Analyze the sentiment of this text and return only a number:\n{query}"}
        ],
        agent_id="sentiment_analysis_agent",
        metadata={"purpose": "sentiment analysis"},
        tags=["nlp", "sentiment"],
        max_tokens=10
    )
    return float(response.choices[0].message.content)

@traced_function
def topic_extraction(query):
    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a topic extraction expert. Identify the main topics in the given text."},
            {"role": "user", "content": f"Extract the main topics from this text and return them as a comma-separated list:\n{query}"}
        ],
        agent_id="topic_extraction_agent",
        metadata={"purpose": "topic extraction"},
        tags=["nlp", "topics"],
        max_tokens=50
    )
    return response.choices[0].message.content.split(", ")

def main():
    query = "Climate change is a pressing issue. Global temperatures are rising, and we need to take action."
    results = analyze_text(query)
    print("\nAnalysis Results:")
    print(results)
    client.end_session()
    print("\nSession ended")

if __name__ == "__main__":
    main()
```

For more detailed examples and advanced usage, check out our [Examples](/examples) section.
